# Results {#results}

In this chapter I present the uncertainty index that I proposed in [Non-Asset-Market Uncertainty Index]. Then, I compare it with the uncertainty indexes from which it comes in [Correlation with Uncertainty Indexes]. After that, I evaluate the relationship between the new index and some real and financial variables in [Estimates on the Impact of Non-Asset-Market Uncertainty Shocks]. In the next stage, I shows how me proposal forecast better that alternative indexes in [Forecasting]. Finally, I perform several robustness exercises in [Robustness].

## Non-Asset-Market Uncertainty Index {#non-asset-market-uncertainty-index}

```{r Import_Uncertainty}
source(here("index", "R", "Import-Uncertainty.R"))
```

```{r uncertainty_indexes, message = FALSE}
uncertainty_indexes <- list(
  economic_policy_uncertainty,
  monetary_policy_uncertainty_BBD,
  monetary_policy_uncertainty_HRS,
  geopolitical_risk_index,
  macro_uncertainty_JLN,
  real_uncertainty_JLN,
  financial_uncertainty_JLN
) %>% 
  reduce(inner_join)
```

```{r dynamic_factors, include = FALSE}
dynamic_factors <- dfm(
  uncertainty_indexes[-1] %>% 
    mutate_all(~ scale(.)),
  , r = 1
  , q = 1
  , p = 1
)

write_rds(
  dynamic_factors, 
  here("index", "Data", "Output", "dynamic_factors.rds")
)

DFM_base <- tibble(
  Date = uncertainty_indexes[["Date"]],
  PCA = dynamic_factors[["pca"]][, 1],
  `Two-step` = dynamic_factors[["twostep"]][, 1],
  QML = dynamic_factors[["qml"]][, 1],
  NAM = (QML - max(QML)) / (QML[1] - max(QML)) * 100
)
```

```{r DescribeIndex}
DescribeIndex <- function(x) {
  m <- mean(x)
  n <- length(x)
  s <- sd(x)
  skew <- sum((x - m)^3 / s^3) / n
  kurt <- sum((x - m)^4 / s^4) / n - 3
  AR <- lm(x ~ dplyr::lag(x))[["coefficients"]][2]
  HL <- log(0.5) / log(abs(AR))
  c(skew, kurt, AR, HL)
}
```

```{r QLR, include = FALSE}
NAM_ts <- ts(DFM_base[["NAM"]], start = c(1985, 1), frequency = 12)

NAM_data <- ts.intersect(NAM_ts, NAM_ts_1 = stats::lag(NAM_ts, k = -1))

QLR <- Fstats(NAM_ts ~ NAM_ts_1, data = NAM_data)

sctest(QLR)
```

```{r date_QLR, include = FALSE}
date_QLR <- breakpoints(NAM_ts ~ NAM_ts_1, data = NAM_data, h = 0.15)
  
coef(date_QLR, breaks = 1)
```

```{r Residuals_break, eval = FALSE}
Residuals_break <- DFM_base %>% 
  mutate(Break = ifelse(Date > ymd("2008-11-30"), 1, 0)) %>% 
  lm(NAM ~ Break, data = .) %>% 
  residuals()

DFM_base %<>% mutate(NAM = Residuals_break)
```

I estimate the non-asset-market uncertainty index following the quasi-maximum likelihood estimator of @dozgianreic:2012 as described in [Dynamic factor model], although alternative estimators are tested in [Robustness]. Moreover, I use one dynamic factor, one static factor and one lag in the specification of the model because I am looking for one single summary index that captures the common comovements of uncertainty, hence, one dynamic and static factor seems appropriate. This binds the lag order to one as the lag order can not be greater that the ratio between the number of static factors and the number of dynamic factors---$p \le \frac{r}{q}$ [@kililutk:2017].

In the Figure \@ref(fig:non-asset-market-uncertainty-index) is presented the non-asset-market index together with the recession dates in the United States as indicated by the National Bureau of Economic Research (NBER) on its website <https://www.nber.org/cycles.html>. The index peaks coincide with well known episodes of uncertainty in the economy as the Black Monday in October 1987, the bursting of the dot-com bubble and the Great Recession 2007--2009 although only the last has considerable impact.

(ref:non-asset-market-uncertainty-index) **Non-Asset-Market Uncertainty Index**: The Figure shows the non-asset-market uncertainty index from January 1985 to July 2017. Grey areas correspond to NBER recession dates (peak-to-trough), including the peaks and troughs. The horizontal line corresponds to the 95 percentile of the empirical distribution of the index. The original measure is scaled to start at 100.

```{r non-asset-market-uncertainty-index, fig.cap = "(ref:non-asset-market-uncertainty-index)", fig.scap = "Non-Asset-Market Uncertainty Index"}
DFM_base %>% 
  ggplot(aes(Date, NAM)) + 
    geom_cycle(fill = "grey50") +
    geom_hline(yintercept = quantile(DFM_base[["NAM"]], 0.95), size = 0.125) +
    geom_line() +
    #ggrepel::geom_label_repel() +
    scale_x_date(date_breaks = "3 year", date_labels = "%Y") +
    scale_y_continuous(limits = c(-100, 600)) +
    labs(
      caption = "Source: Own calculations",
      x = "",
      y = ""
    )
```

<!-- The second estimator used is the Two-Step developed by @dozgianreic:2011. This methods uses PCA estimates and runs them through Kalman filter. -->

<!-- The third estimator used is the Quasi-Maximum Likelihood by @dozgianreic:2012. Similar to two-step estimator, however Kalman filtering procedure is iterated until Expectation-Maximization (EM) algorithm converges. -->

In Table \@ref(tab:summary-table) I report descriptive statistics for the non-asset-market uncertainty index. The skewness, kurtosis, persistence and half-life for the full sample and for two sub-samples are presented (January 1985 to July 2007 and August 2007 to August 2017). This break date was chosen after testing for a break at an unknown date in the autoregressive model of the shocks persistence---AR(1) with drift. The basic idea is to calculate an $F$ statistic---often called Chow statistic, named for its inventor, Gregory Chow [-@chow:1960]---for each conceivable breakpoint in the interval $\tau_{0} = 0.15T$ and $\tau_{1} = 0.85T$, where $T$ is the total number of observations, and reject the null hypothesis of structural stability if the largest of the resulting $F$ statistics exceeds a certain critical value^[That is to say, an $F$ statistic is computed for each potential breakpoint between 1989:M11 and 2012:M9 testing the hypothesis that the coefficients are constant against the alternative that they have different values before and after the breakpoint, omitting the leading and trailing 15 \% of observations.] [@andrews:2003]. This modified Chow test is variously called the Quand Likelihood Ratio (QLR) statistic [@quandt:1960]^[For additional discussion of estimation and testing in the presence of discrete breaks, see @hansen:2001.]. Given that there is evidence for structural change in the model is necessary dating the structural change. Bai and Perron [-@baiperr:1998;-@baiperr:2003]  established a general methodology for estimating breakpoints and their associated confidence intervals in OLS regression. Then, the two periods are choose following this methodology.

The summary statistics in Table  \@ref(tab:summary-table) for the full period are misleading. For the first period of the sample the persistence is less that for the second period, so the time before a shock halve the distance to the stationary mean is smaller. Moreover, the distribution of the uncertainty index is different in location and shape for each period: the first part is slightly asymmetric and it has fewer outliers while the second part has more values above that below the mean and it has several values far from the mean. However, the similarity between both periods is substantial but the shock for the Great Recession in 2007--2009. Therefore, the level of uncertainty is continual in the economy which is related to the knightian framework.



```{r summary-table-raw}
summary_table_raw <- tibble(
  Statistic = c(
    "Skewness", "Excess kurtosis", "Persistence, AR(1)", "Half-life (months)"
  ),
  `1985:M1--2017:M7` = DescribeIndex(
    DFM_base[["NAM"]]
  ),
  `1985:M1--2007:M7` = DescribeIndex(
    DFM_base[DFM_base[["Date"]] <= "2007-07-31", ][["NAM"]]
  ),
  `2007:M8--2017:M7` = DescribeIndex(
    DFM_base[DFM_base[["Date"]] >= "2007-08-31", ][["NAM"]]
  )
)
```

(ref:summary-table) **Summary Statistics of Non-Asset-Market Uncertainty Index in Two Sub-Samples**: The table reports estimates of skewness, kurtosis, first-order autocorrelation coefficient and half-life of an aggregate uncertainty innovation.

```{r summary-table, results = "asis"}
kable(
  summary_table_raw
  , digits = 3,
  , align = c("l", "c", "c", "c")
  , caption = "(ref:summary-table)"
  , caption.short = "Summary Statistics of Non-Asset-Market Uncertainty Index in Two Sub-Samples"
  , booktabs = TRUE
) %>% 
  add_header_above(c("", "Sample period" = 3))
```

```{r scree_plot_values, include = FALSE}
scree_plot <- fa.parallel(
  uncertainty_indexes[-1] %>% 
    mutate_all(~ scale(.)),
  fa = "pc",
  n.iter = 100,
  plot = FALSE, 
  quant = 0.999
)
```

<!-- A scree plot displays the marginal contribution of the kth principal component to the aver- -->
<!-- age R 2 of the N regressions of X t against the first k principal components. This marginal -->
<!-- contribution is the average additional explanatory value of the kth factor. When there are -->
<!-- ^ X , normalized by -->
<!-- no missing data, the scree plot is a plot of the ordered eigenvalues of sum -->
<!-- the sum of the eigenvalues. -->

Although the goal is construct one economic index from the underlying series, it is worthy show the number of components that satisfy several criteria. Each component is associated with an eigenvalue of the correlation matrix of the the raw data. The first principal component (PC) is associated with the largest eigenvalue, the second PC with the second-largest eigenvalue, and so on. The Kaiser-Harris criterion suggests retaining components with eigenvalues greater than 1 unit. Components with eigenvalues less than 1 explain less variance than contained in a single variable. In the Cattel Scree test, the eigenvalues are plotted against their component numbers. Finally, In Parallel Analysis [@haytallescar:2004] are run simulations, extracting eigenvalues from random data matrices of the same size as the original matrix of data. 

The figure \@ref(fig:scree-plot) displays the scree test based on the observed eigenvalues (as dashed line and points), the mean eigenvalues derived from 1000 random data matrices (as dotdashed line), and the eigenvalues greater than 1 (as a horizontal line at $y = 1$). Only the first PC is significantly greater than 1. Likewise, the plot shows a bend and only the PC above this sharp break is retained. Lastly, only the first PC is larger than the average corresponding eigenvalues from a set of random matrices. In summary, all three criteria suggest that a single component is appropriate for summarizing this dataset.

(ref:scree-plot) **Scree Plot for Uncertainty Dataset, 1985--2017**: The Figure shows a scree plot and parallel analysis with 1000 simulations ---all components with eigenvalue greater that simulated value from parallel analysis are fill in black--- which suggest retaining a single component.

```{r scree-plot, fig.cap = "(ref:scree-plot)", fig.scap = "Scree Plot for Uncertainty Dataset, 1985--2017"}
tibble(
  Component_Number = factor(1:length(uncertainty_indexes[-1])), 
  Real = scree_plot[["pc.values"]] / length(uncertainty_indexes[-1]), 
  Parallel = c("choosen", rep("others", length(uncertainty_indexes[-1])))
) %>% 
  ggplot(aes(Component_Number, Real, fill = Parallel)) +
    geom_col() +
    scale_fill_viridis_d(option = "inferno") +
    labs(
      caption = "Source: Own calculations",
      x = "Factor number (principal component number)",
      y = "Fraction of total variance of the series explained"
    ) +
    theme(legend.position = "none")
```

## Correlation with Uncertainty Indexes {#correlation-with-uncertainty-indexes}

```{r corr_indexes, message = FALSE}
corr_indexes <- cor(
  uncertainty_indexes %>%
    inner_join(DFM_base) %>% 
    select(-c(Date, PCA, `Two-step`, QML)) %>% 
    rename(
      `EPU (3C)` = EPU3C,
      `EPU (News)` = EPUNews,
      `MPU (AWN)` = MPU_BBD_AWN,
      `MPU (10)` = MPU_BBD_10,
      `MPU` = MPU_HRS,
      `MU (h = 1)` = MU_JLN_h1,
      `MU (h = 3)` = MU_JLN_h3,
      `MU (h = 12)` = MU_JLN_h12,
      `RU (h = 1)` = RU_JLN_h1,
      `RU (h = 3)` = RU_JLN_h3,
      `RU (h = 12)` = RU_JLN_h12,
      `FU (h = 1)` = FU_JLN_h1,
      `FU (h = 3)` = FU_JLN_h3,
      `FU (h = 12)` = FU_JLN_h12,
      `Non-Asset-Market` = NAM
    )
)
```

(ref:corr-plot) **Corrgram Between Non-Asset-Market Uncertainty Index and Other Uncertainty Indexes**: The Figure shows the correlation between the non-asset-market uncertainty indexes. The variables are defined as: EPU (3C): economic policy uncertainty index from three underlying components, EPU (News): economic policy uncertainty index based on newspaper archives from Access World New's NewsBank service, MPU (AWN): monetary policy uncertainty from draws on hundreds of U.S. newspapers covered by Access World News, MPU (10): monetary policy uncertainty from draws on a balanced panel of 10 major national and regional U.S. newspapers, MPU: monetary policy uncertainty from draws on the Wall Street Journal, New York Times and Washington post, MU (h): macroeconomic uncertainty at h horizon, RU (h): real uncertainty at h horizon, FU (h): financial uncertainty at h horizon and Non-Asset-Market: the uncertainty index propose in this document.

```{r corr-plot, fig.asp = 0.85, fig.cap = "(ref:corr-plot)", fig.scap = "Corrgram Between Non-Asset-Market Uncertainty Index and Other Uncertainty Indexes"}
corrplot(
  corr_indexes,
  method = "color", 
  type = "lower",
  col = viridis(20, option = "B"),
  order = "FPC", 
  tl.cex = 0.8,
  tl.col = "black",
  tl.offset = 1,
  tl.srt = 360,
  cl.cex = 0.8,
  cl.offset = 0.9,
  cl.length = 11, 
  cl.ratio = 0.2
)
```

To interpret the Figure \@ref(fig:corr-plot), a light color represent a positive correlation between the two variables that meet at that cell. Conversely, a dark color represent a negative correlation. More saturated the color, the greater the magnitude of the correlation. Also, the rows and columns have been reordered (using principal components analysis as explained in @friendly:2002 for corrgrams) to cluster variables together that have similar correlation patterns. It is see that from the shaded cells that the non-asset-market uncertainty index is much more correlated with the econometrics measures of uncertainty and less with the newspaper-based measures of uncertainty.

## Estimates on the Impact of Non-Asset-Market Uncertainty Shocks {#var-baseline}

Following the model proposed by @chrieichevan:2005 ---and used as a base in @chulguilurib:2017--- the characterization of monetary policy is defined by:

\begin{equation}
    R_{t} = f(\Omega_{t}) + \epsilon_{t} (\#eq:R)
\end{equation}

Where, $R_ {t}$ is the effective federal funds rate, $f$ is a linear function, $\Omega_{t}$ is a set of information and $\epsilon_{t}$ is the monetary policy shock ---where it is assumed that $\epsilon_{t}$ is orthogonal to $\Omega_{t}$.

Considering $Y_{t}$ as the set of variables to which the dynamic effect of a monetary policy shock will be analyzed, there is:

\begin{equation}
    Y_{t} = [Y_{1t}, R_{t}, Y_{2t}]' (\#eq:variables)
\end{equation}

The vector $Y_{1t}$ is composed of the variables whose values at the moment $t$ are contained in $\Omega_{t}$ and it is assumed that they do not respond simultaneously to a monetary policy shock: production, employment, consumption , inflation, new orders and working hours. The vector $Y_{2t}$ consists of the values at the moment $t$ of all the other variables in $\Omega_{t}$, which simultaneously respond to a monetary policy shock: Standard \& Poor's 500 and Mass monetary (M2).

```{r Import_USA_Data}
source(here("index", "R", "Import-USA-Data.R"))
```

```{r VAR_data, message = FALSE}
VAR_data <- USA_data %>% 
  inner_join(uncertainty_indexes) %>% 
  inner_join(DFM_base)
```

```{r chosen_variables}
chosen_variables <- c(
  "Production_all_log_cycle",
  "Employment_all_lin_cycle",
  "Consumption_log_cycle",
  "Inflation_cycle",
  "NewOrders_log_cycle",
  "Wages_all_log_cycle",
  "Labor_all_lin_cycle",
  "FederalFundsRate_lin_cycle",
  "StockMarketIndex_log_cycle",
  "M2_cca_cycle",
  "NAM"
)
```

```{r VAR_baseline_lag}
VAR_baseline_lag <- VARselect(
  VAR_data %>% select(!!!chosen_variables),
  lag.max = 12
)
```

```{r VAR_baseline}
VAR_baseline <- VAR(
  VAR_data %>% select(!!!chosen_variables),
  p = 12
)
```

```{r irf_baseline, warning = FALSE}
irf_baseline <- irf(
  VAR_baseline,
  impulse = "NAM",
  n.ahead = 60,
  runs = 100,
  ci = 0.86
)
```

```{r irf_baseline_matrix}
matrix_response <- as_tibble(irf_baseline[["irf"]][["NAM"]]) %>%
  mutate(Months = row_number()) %>%
  gather(-Months, key = "Variable", value = "Response")

matrix_lower <- as_tibble(irf_baseline[["Lower"]][["NAM"]]) %>%
  mutate(Months = row_number()) %>%
  gather(-Months, key = "Variable", value = "Lower")

matrix_upper <- as_tibble(irf_baseline[["Upper"]][["NAM"]]) %>%
  mutate(Months = row_number()) %>%
  gather(-Months, key = "Variable", value = "Upper")

matrix_irf <- list(matrix_response, matrix_lower, matrix_upper) %>%
  reduce(inner_join, by  = c("Variable", "Months")) %>%
  select(Variable, Months, Response, Lower, Upper) %>%
  arrange(Variable, Months) %>%
  mutate(
    Variable = factor(Variable),
    Variable = fct_recode(
      Variable,
      "Production" = "Production_all_log_cycle",
      "Employment" = "Employment_all_lin_cycle",
      "New Orders" = "NewOrders_log_cycle",
      "Consumption" = "Consumption_log_cycle",
      "Federal Funds Rate" = "FederalFundsRate_lin_cycle",
      "Stock Market Index" = "StockMarketIndex_log_cycle"
    )
  )
```

(ref:irf-baseline-plot) **Economic Dynamics Under Uncertainty**: The Figure shows the reaction of the variables to an unexpected increment of non-asset-market uncertainty, based on 1000 replications. The estimation period runs from January 1985 to July 2017. The axes are in percentages but the federal funds rate and employment are in basic points. Confidence bands (86 \%) are calculated using bootstrapping techniques as explained in @efrotibs:1993.

```{r irf-baseline-plot, fig.asp = 1.236, fig.cap = "(ref:irf-baseline-plot)", fig.scap = "Economic Dynamics under Uncertainty"}
matrix_irf %>%
  filter(Variable %in% c(
    "Production",
    "Employment",
    "New Orders",
    "Consumption",
    "Federal Funds Rate",
    "Stock Market Index"
  )) %>%
  ggplot(aes(Months, Response)) +
    geom_hline(aes(yintercept = 0), size = 0.125) +
    geom_ribbon(
      aes(ymin = Lower, ymax = Upper), 
      fill = "steelblue", 
      alpha = 0.125
    ) +
    geom_line(colour = "steelblue", linetype = "dashed") +
    scale_x_continuous(breaks = seq(0, 60, by = 10)) +
    facet_wrap(
      ~ Variable,
      nrow = 3,
      scales = "free_y",
    ) +
    labs(
      caption = "Source: Own calculations",
      x = "Months after the shock",
      y = "Impact"
    )
```

```{r fevd_medium, warning = FALSE}
fevd_baseline <- fevd(VAR_baseline, 60)
```

```{r fevd_medium_production}
fevd_baseline_production <- as_tibble(
  fevd_baseline[["Production_all_log_cycle"]]
)

fevd_baseline_production %<>%
  rename(
    Production = Production_all_log_cycle,
    Employment = Employment_all_lin_cycle,
    Prices = Inflation_cycle,
    Wages = Wages_all_log_cycle,
    Labor = Labor_all_lin_cycle,
    `Federal funds rate` = FederalFundsRate_lin_cycle,
    `Stock market index` = StockMarketIndex_log_cycle,
    Uncertainty = NAM
  ) %>%
  mutate(N = row_number()) %>%
  gather(Production:Uncertainty, key = "Variable", value = "Percentage") %>%
  mutate(Variable = factor(Variable, levels = unique(Variable))) %>%
  arrange(N)
```

```{r fevd_medium_R}
fevd_baseline_R <- as_tibble(
  fevd_baseline[["FederalFundsRate_lin_cycle"]]
)

fevd_baseline_R %<>%
  rename(
    Production = Production_all_log_cycle,
    Employment = Employment_all_lin_cycle,
    Prices = Inflation_cycle,
    Wages = Wages_all_log_cycle,
    Labor = Labor_all_lin_cycle,
    `Federal funds rate` = FederalFundsRate_lin_cycle,
    `Stock market index` = StockMarketIndex_log_cycle,
    Uncertainty = NAM
  ) %>%
  mutate(N = row_number()) %>%
  gather(Production:Uncertainty, key = "Variable", value = "Percentage") %>%
  mutate(Variable = factor(Variable, levels = unique(Variable))) %>%
  arrange(N)
```

(ref:fevd-medium-production) **Forecast error variance decomposition for production**: The Figure shows fractions of the forecast error variance due to production shocks for the eight variables. The sample period is January 1985 to July 2017.

```{r fevd-medium-production-plot, fig.cap = "(ref:fevd-medium-production)", fig.scap = "Forecast error variance decomposition for production", out.extra = ""}
fevd_baseline_production %>%
  ggplot(aes(N, Percentage)) +
    geom_area(aes(fill = Variable), colour = "black", size = 0.20) +
    scale_y_continuous(breaks = seq(0, 1, by = 0.10), labels = percent) +
    scale_x_continuous(breaks = c(1, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60)) +
    scale_fill_viridis_d(option = "inferno") +
    labs(
    caption = "Source: Own calculations",
    x = "Horizon",
    y = "",
    fill = ""
    )
```

(ref:fevd-medium-R-plot) **Forecast error variance decomposition for federal funds rate**: The Figure shows fractions of the forecast error variance due to federal funds rate shocks for the eight variables. The sample period is January 1985 to July 2017.

```{r fevd-medium-R-plot, fig.cap = "(ref:fevd-medium-R-plot)", fig.scap = "Forecast error variance decomposition for federal funds rate", out.extra = ""}
fevd_baseline_R %>%
  ggplot(aes(N, Percentage)) +
    geom_area(aes(fill = Variable), colour = "black", size = 0.20) +
    scale_y_continuous(breaks = seq(0, 1, by = 0.10), labels = percent) +
    scale_x_continuous(breaks = c(1, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60)) +
    scale_fill_viridis_d(option = "inferno") +
    labs(
    caption = "Source: Own calculations",
    x = "Horizon",
    y = "",
    fill = ""
    )
```

```{r Granger}
Granger <- function(Cause) {
  causality(VAR_baseline, cause = Cause)[["Granger"]][["p.value"]]
}
```

```{r Names_VAR}
Names_VAR <-   c(
  "Production",
  "Employment",
  "Consumption",
  "Inflation",
  "New Orders",
  "Wages",
  "Labor",
  "Federal Funds rate",
  "Stock market index",
  "M2",
  "Non-Asset-Market Uncertainty"
)
```

```{r p_values_granger}
p_values_granger <- map_dbl(chosen_variables, Granger)
```

(ref:Granger-table) **Granger-Causality Tests**: The entries show the $p$-values for F-tests that lags of the variable in the row labeled *Regressor* do not enter the reduced form equation for all remaining variables.

```{r Granger-table, results = "asis"}
knitr::kable(
  tibble(
    Regressor = Names_VAR,
    `p-values` = p_values_granger
  )
  , digits = 2,
  , align = c("l", "c"),
  , caption = "(ref:Granger-table)"
  , caption.short = "Granger-Causality Tests",
  , booktabs = TRUE
  , linesep = ""
)
```

## Forecasting {#forecasting}

Evaluation of the forecasting capabilities of the VAR model using differents uncertainty indexes is carried on with multistep-ahead forecast, computed by iterating forward the reduced form VAR, in the Table \@ref(tab:rmsfe-non-asset-market). The core idea of an iterated forecast is that a VAR model is used to make a forecast one period ahead ($T + 1$) using data through period $T$. Then the model is used to make a forecast for date $T + 2$, given the data through date $T$, where the forecasted value for date $T + 1$ is treated as data for the purpose of making the forecast for period $T + 2$. Therefore, the one-step ahead forecast is used as an intermediate step to make the two-step ahead forecast. This process is iterated until the forecast is made for the desired forecast horizon $h$. In other words, to compute multistep iterated VAR forecasts $h$ steps ahead, it is necessary to compute forecasts of all variables for all intervening periods between $T$ and $T + h$. Seeing that the ultimate test of a forecasting model is its out-of-sample performance, \@ref(tab:rmsfe-non-asset-market) focuses on pseudo out-of-sample forecasts over the period from 1985:M1 to 2017:M7 ---that is the \% 10 of the sample. It examines forecast horizons of three months, six months, nine months and twelve months. 

Table \@ref(tab:rmsfe-non-asset-market) shows the root mean square forecast error for each of the forecasting methods using a different uncertainty index. The mean squared forecast error is computed as the average squared value of the forecast error over the 1985--2017 out-of-sample period, and the resulting square root is the mean squared forecast error reported in the table. For instance, Table \@ref(tab:rmsfe-non-asset-market) indicates that the VAR model with the non-asset market index as last variable improves upon the VAR models with the economic policy uncertainty or macroeconomic uncertainty in replace. Specifically, the forecast method with the non-asset market uncertainty index has lower error for employment, labor and stock market index over the two remaining models and for production, wages and federal funds rate is the second best.

```{r EndOfSample}
# End of sample dates
EndOfSample <- VAR_data %>%
  tail(nrow(.) - quantile(1:nrow(.), 0.90) + 1) %>%
  pull(Date)
```

```{r forecast_horizont}
forecast_horizont <- list(3, 6, 12, 24)
```

```{r indexes}
indexes <- c("NAM", "EPU3C", "MU_JLN_h1")
```

```{r Forecast_Error}
Forecast_Error <- function(end_date, h, index) {
  # Model variables
  model_variables <- c(
    "Production_NAICS_log_cycle",
    "Employment_manu_lin_cycle",
    "Inflation_urban_cycle",
    "Wages_manu_log_cycle",
    "Labor_manu_lin_cycle",
    "FederalFundsRate_lin_cycle",
    "StockMarketIndex_log_cycle"
  )
  
  variables <- c(model_variables, index)  
  
  # Estimate VAR model
  VAR_model <- VAR(
    VAR_data %>%
      filter(Date <= end_date) %>%
      select(!!!variables), 
    p = 12
  )

  # Sample data for n-period ahead forecast
  raw_data <- VAR_data %>%
    filter(
      between(
        Date,
        ceiling_date(end_date %m+% months(1), unit = "month") - days(1),
        ceiling_date(end_date %m+% months(h), unit = "month") - days(1)
      )
    ) %>%
    select(!!!variables)

  # Compute forecast
  raw_predictions <- bind_rows(
    predict(VAR_model, n.ahead = h)[["fcst"]],
    .id = "column_label"
  ) %>%
    head(h) %>%
    select(-column_label)

  # Compute pseudo-out-of-sample forecast errors
  raw_data - raw_predictions
}
```

```{r rmsfe}
rmsfe <- function(h, index) {
  rmsfe_raw <- map_dfr(
    EndOfSample %>% head(-h),
    Forecast_Error,
    h = h,
    index = index
  ) %>%
  summarise_all(~sqrt(mean(.)^2))

  rmsfe_raw
}
```

```{r rmsfe_indexes}
rmsfe_indexes <- function(index) {
  rmsfe_tibble <- map_dfr(
    forecast_horizont,
    rmsfe,
    index = index
  )
  
  rmsfe_tibble
}
```

```{r rmsfe_table}
rmsfe_table <- map_dfr(
  indexes,
  rmsfe_indexes, 
  .id = "label"
)

rmsfe_table %<>% 
  select(-(NAM:MU_JLN_h1)) %>% 
  select(-label) %>% 
  rename(
    Production = Production_NAICS_log_cycle,
    Employment = Employment_manu_lin_cycle,
    Labor = Labor_manu_lin_cycle,
    Inflation = Inflation_urban_cycle,
    Wages = Wages_manu_log_cycle,
    `Federal funds rate` = FederalFundsRate_lin_cycle,
    `Stock market index` = StockMarketIndex_log_cycle,
  ) %>%
  mutate(
    `Forecast horizont` = factor(rep(str_c(forecast_horizont, " months"), 3))
  ) %>% 
  select(`Forecast horizont`, everything())
```

(ref:rmsfe-non-asset-market) **Root Mean Squared Errors of Simulated Out-Of-Sample Forecasts, 1985:M1--2017:M7**: Entries are the root mean squared error of forecasts computed recursively for vector autoregressions with different uncertainty index (models with 12 fixed lags following Leeb \& Pötscher [-@leebpots:2005;-@leebpots:2006], as explained in [Lag order]). Each model was estimated using data from 1985:M1 through the beginning of the forecast period.

```{r rmsfe-non-asset-market, results = "asis"}
kable(
  rmsfe_table
  , digits = 2,
  , align = c(rep("c", 8))
  , caption = "(ref:rmsfe-non-asset-market)"
  , caption.short = "Root Mean Squared Errors of Simulated Out-Of-Sample Forecasts"
  , booktabs = TRUE
  , linesep = ""
) %>% 
  kable_styling(full_width = TRUE) %>% 
  pack_rows(index = c(
    "Non-asset-market uncertainty index" = 4, 
    "Economic policy uncertainty index" = 4, 
    "Macroeconomic uncertainty index" = 4)
  , latex_gap_space = "2em"
  ) %>% 
  landscape() 
```

## Robustness {#robustness}

I perform several robustness exercises varying the econometric methodology employed to create the non-asset-market uncertainty index. I estimate the uncertainty index using PCA and PCA estimates runs through Kalman ﬁlter ---two-step--- instead of quasi-maximum likelihood. The results are summarized in Figure \@ref(fig:robustness-methods). In general, the uncertainty index behaves in a very similar fashion, regardless of the factor methodology used to summarize the components of the series.

In the same way I employ different variable sets and orderings of the VAR estimated in [Estimates on the Impact of Non-Asset-Market Uncertainty Shocks]. First, I change the sector of the variables to the manufacturing sector with eight variables following @bloom:2009. The VAR estimations are run using monthly data from 1985 through July 2017. The variables in the estimation order are log industrial production in manufacturing, employment in manufacturing, average hours in manufacturing, log consumer price index (all urban consumers), log average hourly earnings for production workers in manufacturing, federal funds rate, stock-market index and non-asset-market uncertainty. The ordering is based on the assumptions that shocks instantaneously influence the stock market, then prices (wages, the consumer price index (CPI), and interest rates), and finally quantities (hours, employment, and output). All variables are Hamilton detrended with a look-ahead period of two years ($h = 24$), as explained in [Detrend].

Figure \@ref(fig:production-medium) plots the impulse response function of industrial production (the dashed line) to a non-asset-market uncertainty shock. Industrial production displays a fall of around 0.85 \% within 15 months. The confidence bands (shaded area) are plotted around this, highlighting that this drop is statistically significant. For comparison to a first-moment shock, the response to a impulse to the federal funds rate is also plotted (dotted line) displaying a minor drop over the subsequent 2 years^[The response to a fall the stock-market (not plotted) is similar in size and magnitude to the response to a rise in the federal funds rate.]. Figure \@ref(fig:employment-medium) repeats the same exercise for employment, displaying a similar drop in activity.

In Figure \@ref(fig:robustness), the VAR results are show to be robust to a variety of alternative variables sets and orderings. The VAR is reestimated using a simple trivariate VAR (log industrial production in manufacturing, employment in manufacturing and non-asset-market uncertainty index only) also display a drop (dashed line). The "quadvariate" VAR (log industrial production in manufacturing, employment in manufacturing, stock-market index and non-asset-market uncertainty index only) also displays a similar drop (solid line), as does the quadvariate VAR with the variable ordering reversed (dotted line). Hence the response of industrial production to a uncertainty shock appears robust to both the basic selection and the ordering of variables.

Henceforth, Figures \@ref(fig:robustness-methods), \@ref(fig:production-medium), \@ref(fig:employment-medium) and \@ref(fig:robustness) confirm the robustness of the DFM to the methodology used and of VAR results to a range of alternative approaches over variable ordering and variable inclusion.

(ref:robustness-methods) **Robustness to Estimation Method**: The figure shows the comparison between the non-asset-market uncertainty index using quasi-maximum likelihood [@dozgianreic:2012], principal components [@stocwats:2002] and two-step [@dozgianreic:2011]. All the indexes have been standardized to make proper comparisons.

```{r robustness-methods, fig.cap = "(ref:robustness-methods)", fig.scap = "Robustness to Estimation Method"}
DFM_base %>% 
  mutate(
    PCA = (PCA - max(PCA)) / (PCA[1] - max(PCA)) * 100,
    `Two-step` = (
      (`Two-step` - max(`Two-step`)) / (`Two-step`[1] - max(`Two-step`)) * 100
    ),
    QML = (QML - max(QML)) / (QML[1] - max(QML)) * 100
  ) %>% 
  gather(PCA:QML, key = "Method", value = "Index") %>% 
  ggplot(aes(Date, Index)) +
    geom_cycle(fill = "grey50") +
    geom_line(aes(colour = Method)) +
    scale_x_date(date_breaks = "3 year", date_labels = "%Y") +
    scale_y_continuous(limits = c(-100, 600)) +
    scale_colour_viridis_d(option = "inferno") +
    labs(
      caption = "Source: Own calculations",
      x = "",
      y = ""
    )
```

```{r chosen_variables_eight}
chosen_variables_eight <- c(
  "Production_NAICS_log_cycle",
  "Employment_manu_lin_cycle",
  "Inflation_urban_cycle",
  "Wages_manu_log_cycle",
  "Labor_manu_lin_cycle",
  "FederalFundsRate_lin_cycle",
  "StockMarketIndex_log_cycle",
  "NAM"
)
```

```{r var_medium_lag}
VAR_medium_lag <- VARselect(
  VAR_data %>% select(!!!chosen_variables_eight),
  lag.max = 24
)
```

```{r VAR_medium}
VAR_medium <- VAR(
  VAR_data %>% select(!!!chosen_variables_eight),
  p = 12
)
```

```{r irf_medium_production, warning = FALSE}
irf_medium_production <- irf(
  VAR_medium,
  impulse = c("NAM", "FederalFundsRate_lin_cycle"),
  response = "Production_NAICS_log_cycle",
  n.ahead = 60,
  runs = 100,
  ci = 0.86
)
```

```{r irf_medium_production_matrix}
irf_medium_production_matrix <- tibble(
  Months = 0:60,
  `Response to a non-asset-market uncertainty shock` = as.vector(
    irf_medium_production[["irf"]][["NAM"]]
  ),
  NAM_lower = as.vector(irf_medium_production[["Lower"]][["NAM"]]),
  NAM_upper = as.vector(irf_medium_production[["Upper"]][["NAM"]]),
  `Response to a federal funds rate shock` = -as.vector(
    irf_medium_production[["irf"]][["FederalFundsRate_lin_cycle"]]
  )
) %>%
  gather(
    `Response to a non-asset-market uncertainty shock`,
    `Response to a federal funds rate shock`,
    key = "Imp",
    value = "Res"
  )
```

(ref:production-medium) **Decline of Production Under Uncertainty in the Eight Variable VAR**: The Figure shows the reaction of industrial production in manufacturing to an unexpected increment of non-asset-market uncertainty and to an unexpected increment of the federal funds rate (model with 12 fixed lags following Leeb \& Pötscher [-@leebpots:2005;-@leebpots:2006], as explained in [Lag order]), based on 1000 replications. The estimation period runs from January 1985 to July 2017. The axe is in percentage. Confidence bands (86 \%) are calculated using bootstrapping techniques as explained in @efrotibs:1993.

```{r production-medium, fig.cap = "(ref:production-medium)", fig.scap = "Decline of Production Under Uncertainty in the Eight Variable VAR"}
irf_medium_production_matrix %>%
  ggplot(aes(Months, Res)) +
    geom_hline(aes(yintercept = 0), size = 0.125) +
    geom_ribbon(
      data = irf_medium_production_matrix %>% 
        filter(Imp == "Response to a non-asset-market uncertainty shock"),
      aes(ymin = NAM_lower, ymax = NAM_upper),
      fill = "steelblue",
      alpha = 0.125
    ) +
    geom_line(aes(colour = Imp, linetype = Imp)) +
    scale_x_continuous(breaks = seq(0, 60, by = 5)) +
    scale_y_continuous(breaks = seq(0.55, -0.95, by = -0.15)) +
    scale_color_manual(values = c(inferno(1), "steelblue")) +
    scale_linetype_manual(values = c("dotdash", "dashed")) +
    labs(
      caption = "Source: Own calculations",
      x = "Months after the shock",
      y = "% impact on production",
      colour = "",
      linetype = ""
    ) +
    theme(legend.position = "bottom")
```

```{r irf_medium_employment, warning = FALSE}
irf_medium_employment <- irf(
  VAR_medium,
  impulse = c("NAM", "FederalFundsRate_lin_cycle"),
  response = "Employment_manu_lin_cycle",
  n.ahead = 60,
  runs = 100,
  ci = 0.86
)
```

```{r irf_medium_employment_matrix}
irf_medium_employment_matrix <- tibble(
  Months = 0:60,
  `Response to a non-asset-market uncertainty shock` = as.vector(
    irf_medium_employment[["irf"]][["NAM"]]
  ),
  NAM_lower = as.vector(irf_medium_employment[["Lower"]][["NAM"]]),
  NAM_upper = as.vector(irf_medium_employment[["Upper"]][["NAM"]]),
  `Response to a federal funds rate shock` = -as.vector(
    irf_medium_employment[["irf"]][["FederalFundsRate_lin_cycle"]]
  )
) %>%
  gather(
    `Response to a non-asset-market uncertainty shock`,
    `Response to a federal funds rate shock`,
    key = "Imp",
    value = "Res"
  )
```

(ref:employment-medium) **Decline of Employment Under Uncertainty in the Eight Variable VAR**: The Figure shows the reaction of employment in manufacturing to an unexpected increment of non-asset-market uncertainty and to an unexpected increment of the federal funds rate (model with 12 fixed lags following Leeb \& Pötscher [-@leebpots:2005;-@leebpots:2006], as explained in [Lag order]), based on 1000 replications. The estimation period runs from January 1985 to July 2017. The axle is in percentage. Confidence bands (86 \%) are calculated using bootstrapping techniques as explained in @efrotibs:1993.

```{r employment-medium, fig.cap = "(ref:employment-medium)", fig.scap = "Decline of Employment Under Uncertainty in the Eight Variable VAR"}
irf_medium_employment_matrix %>%
  ggplot(aes(Months, Res)) +
    geom_hline(aes(yintercept = 0), size = 0.125) +
    geom_ribbon(
      data = irf_medium_employment_matrix %>%
        filter(Imp == "Response to a non-asset-market uncertainty shock"),
      aes(ymin = NAM_lower, ymax = NAM_upper),
      fill = "steelblue",
      alpha = 0.125
    ) +
    geom_line(aes(colour = Imp, linetype = Imp)) +
    scale_x_continuous(breaks = seq(0, 60, by = 5)) +
    scale_y_continuous(breaks = seq(60, -90, by = -15)) +
    scale_color_manual(values = c(inferno(1), "steelblue")) +
    scale_linetype_manual(values = c("dotdash", "dashed")) +
    labs(
      caption = "Source: Own calculations",
      x = "Months after the shock",
      y = "Impact on employment",
      colour = "",
      linetype = ""
    ) +
    theme(legend.position = "bottom")
```

```{r VAR_trivariate_lag}
VAR_trivariate_lag <- VARselect(
  VAR_data %>% select(
    Production_NAICS_log_cycle,
    Employment_manu_lin_cycle,
    NAM
  ),
  lag.max = 24
)
```

```{r VAR_trivariate}
VAR_trivariate <- VAR(
  VAR_data %>% select(
    Production_NAICS_log_cycle,
    Employment_manu_lin_cycle,
    NAM
  ),
  p = 12
)
```

```{r irf_trivariate, warning = FALSE}
irf_trivariate <- irf(
  VAR_trivariate,
  impulse = "NAM",
  response = "Production_NAICS_log_cycle",
  n.ahead = 60,
  runs = 100,
  ci = 0.86
)
```

```{r VAR_quadvariate}
VAR_quadvariate <- VAR(
  VAR_data %>% select(
    Production_NAICS_log_cycle,
    Employment_manu_lin_cycle,
    StockMarketIndex_log_cycle,
    NAM
  ),
  p = 12
)
```

```{r irf_quadvariate, warning = FALSE}
irf_quadvariate <- irf(
  VAR_quadvariate,
  impulse = "NAM",
  response = "Production_NAICS_log_cycle",
  n.ahead = 60,
  runs = 100,
  ci = 0.86
)
```

```{r VAR_quadvariate_reverse}
VAR_quadvariate_reverse <- VAR(
  VAR_data %>% select(
    NAM,
    StockMarketIndex_log_cycle,
    Employment_manu_lin_cycle,
    Production_NAICS_log_cycle
  ),
  p = 12
)
```

```{r irf_quadvariate_reverse, warning = FALSE}
irf_quadvariate_reverse <- irf(
  VAR_quadvariate_reverse,
  impulse = "NAM",
  response = "Production_NAICS_log_cycle",
  n.ahead = 60,
  runs = 100,
  ci = 0.86
)
```

(ref:robustness) **VAR Model is Robust to Different Variable Sets and Ordering**: The Figure shows the reaction of the industrial production to an unexpected increment of non-asset-market uncertainty. The estimation period runs from January 1985 to July 2017. The axle is in percentage. The models are defined as: trivariate (industrial production, employment and non-asset-market uncertainty shocks), Quadvariate (industrial production, employment, stock-market and non-asset-market uncertainty shocks) and Quadvariate in reverse (non-asset-market uncertainty shocks, stock-market, employment and industrial production).

```{r robustness, fig.cap = "(ref:robustness)", fig.scap = "VAR Model is Robust to Different Variable Sets and Ordering"}
tibble(
  Months = 0:60,
  Trivariate = irf_trivariate[["irf"]][["NAM"]],
  Quadvariate = irf_quadvariate[["irf"]][["NAM"]],
  `Quadvariate in reverse` = irf_quadvariate_reverse[["irf"]][["NAM"]]
) %>%
  gather(
    Trivariate, Quadvariate, `Quadvariate in reverse`,
    key = "VAR",
    value = "Shock"
  ) %>%
  ggplot(aes(Months, Shock)) +
    geom_hline(aes(yintercept = 0), size = 0.125) +
    geom_line(aes(colour = VAR, linetype = VAR)) +
    scale_x_continuous(breaks = seq(0, 60, by = 5)) +
    scale_y_continuous(breaks = seq(0, -1.50, by = -0.25)) +
    scale_color_viridis_d(option = "inferno") +
    labs(
      caption = "Source: Own calculations",
      x = "Months after the shock",
      y = "% impact on production",
      colour = "",
      linetype = ""
    ) +
    theme(legend.position = "bottom")
```
